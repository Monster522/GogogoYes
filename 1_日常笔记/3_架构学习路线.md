## 后端服务知识体系

- 主要分为：高性能、高可用、数据一致性、安全性、软件架构、DevOps

### 1.高性能

- **指标**

  QPS、并发数、响应时间

### 2.高可用

- **范畴**

  1. 柔性
  2. 流量控制
  3. 监控：告警、故障识别与自动处理
  4. 集群：负载均衡、扩容缩容

- **常见案例**

  1. 接入层：GSLB
  2. 逻辑层：无状态服务、有状态服务
  3. 数据层：主从模式、MGR、备灾（异地备灾/两地三中心/三地五中心）

- **参考资料**

  https://chongit.github.io/2015/04/15/GSLB%E6%A6%82%E8%A6%81%E5%92%8C%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/

  https://www.cnblogs.com/kevingrace/p/10470226.html

### 3.数据一致性

- **冗余引入**

  1. 中心化副本控制协议

     ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/20200903143255.png)

  2. 去中心化副本控制协议

     ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903143720.png)

- **缓存引入**

  1. Cache Aside Pattern

     ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903160010.png)

  2. 分布式缓存协议-读多写少

     ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903160146.png)

### 4.安全性

- **接口安全**
  1. 防窃听
  2. 防篡改
  3. 防重放
  4. 防冒充
- **数据安全**
  1. 泄密
  2. SQL注入
- **网络安全**
  1. DDOS
  2. 域名劫持
- **权限系统**
  1. 主态和客态
  2. 角色和权限

### 5.软件架构

- **层次拆分**
  1. 数据层：数据接入层、缓存代理层
  2. 逻辑层：基础功能层、业务逻辑层、聚合服务层
  3. 接入层：四层接入、七层接入
- **垂直拆分**
  1. 按功能划分
  2. 高内聚、低耦合
- **微服务和中台**

### 6.DevOps

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903165303.png)

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903165334.png)

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903165352.png)

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903165407.png)



## 高性能设计思路

### 1.硬件层面-缓存

- **静态数据-读多写少**
  1. 定期更新
  2. 修改操作触发更新
  3. 判断为脏后更新
- **动态数据-写多**
  1. 重要数据，立刻回写
  2. 次要数据，定期回写

### 2.硬件层面-无锁化

- 利用硬件支持的原子操作可以实现无锁的数据结构，很多语言都提供CAS原子操作（如go中的atomic包和C++11中的atomic库），可以用于实现无锁队列。

```c++
// 加锁
template<typename T>
class WithLockList
{
    mutex mtx;
    Node<T> *head;
public:
    void pushFront(const T &value)
    {
        auto *node = new Node<T>(value);
        lock_guard<mutex> lock(mtx); //①
        node->next = head;
        head = node;
    }
};

//  不加锁
template<typename T>
class LockFreeList
{
    atomic<Node<T> *> head;
public:
    void pushFront(const T &value)
    {
        auto *node = new Node<T>(value);
        node->next = head.load();
        while(!head.compare_exchange_weak(node->next, node)); //②
    }
};
```

### 3.操作系统-零拷贝

- **定义**

  1. 零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。
  2. 作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。
  3. 实现零拷贝用到的最主要技术是 DMA 数据传输技术和内存区域映射技术。

- **作用**

  1. 零拷贝机制可以减少数据在内核缓冲区和用户进程缓冲区之间反复的 I/O 拷贝操作。

  2. 零拷贝机制可以减少用户进程地址空间和内核地址空间之间因为上下文切换而带来的 CPU 开销。

#### 3.1 传统IO方式实现

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903171502.png)

- **读取文件，再用socket发送出去。先读取、再发送，实际经过1~4四次copy。**

  ```java
  filefd = open(...); //打开文件
  sockfd = socket(...); //打开socket
  buffer = new buffer(...); //创建buffer
read(filefd, buffer); //从文件内容读到buffer中
  write(sockfd, buffer); //将buffer中的内容发送到网络
  ```
  
  1. 将磁盘文件，读取到操作系统内核缓冲区。
  2. 将内核缓冲区的数据，copy到application应用程序的buffer。
  3. 将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)。
  4. 将socket buffer的数据，copy到网卡，由网卡进行网络传输。
  
- **缺点**

  1. 读取磁盘文件并进行网络发送，经过的四次数据copy是非常繁琐的。
  2. 实际上并不需要第二个和第三个数据副本。应用程序除了缓存数据并将其传输回套接字缓冲区之外什么都不做。相反，数据可以直接从读缓冲区传输到套接字缓冲区。

- **零拷贝的改进**

  1. 指读取磁盘文件后，不需要做其他处理，直接用网络发送出去。如果读取磁盘的数据需要用程序进一步处理的话，必须要经过第二次和第三次数据copy，让应用程序在内存缓冲区处理。
  2. Linux内核提供/实现零拷贝的API：sendfile和mmap

#### 3.2 mmap

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903171455.png)

- **定义**

  1. 将磁盘文件映射到内存, 用户通过修改内存就能修改磁盘文件。
  2. 工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后对物理内存的操作会被同步到硬盘上(操作系统在适当的时候)。
  3. 通过mmap，进程像读写硬盘一样读写内存(当然是虚拟机内存)，也不必关心内存的大小，有虚拟内存兜底。

  ```java
  filefd = open(...); //打开文件
  sockfd = socket(...); //打开socket
  buffer = mmap(filefd); //将文件映射到进程空间
  write(sockfd, buffer); //将buffer中的内容发送到网络
  ```

  

- **缺点**

  1. 不可靠。写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。

#### 3.3 sendfile

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903171434.png)

- **定义**

  1. Linux 2.4+ 内核通过 sendfile 系统调用，提供了零拷贝。磁盘数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer(socket buffer)，无需 CPU 拷贝。
  2. 除了减少数据拷贝外，整个读文件 - 网络发送由一个 sendfile 调用完成，整个过程只有两次上下文切换，因此大大提高了性能。
  3. 直接从内核空间（DMA的）到内核空间（Socket的)、然后发送网卡。
  4. sendfile(in,out)就是，磁盘文件读取到操作系统内核缓冲区后、直接扔给网卡，发送网络数据。应用的场景非常多，如Tomcat、Nginx、Apache等web服务器返回静态资源等，将数据用网络发送出去，都运用了sendfile。

  ```java
  filefd = open(...); //打开文件
  sockfd = socket(...); //打开socket
  sendfile(sockfd, filefd); //将文件内容发送到网络
  ```



### 4.操作系统-协程

- **多并发的方式有：进程、线程、协程**

  1. 轻量级的协程, 栈初始2KB, 调度不涉及系统调用.
  2. 调度在计算机中是分配工作所需资源的方法. linux的调度为CPU找到可运行的线程. 而Go的调度是为M(线程)找到P(内存, 执行票据)和可运行的G.
  3. 用户函数调用前会检查栈空间是否足够, 不够的话, 会进行*2 栈扩容. 最大栈1G, 超出panic.
  4. 用户代码中的协程同步造成的阻塞, 仅仅是切换(gopark)协程, 而不阻塞线程, m和p仍结合, 去寻找新的可执行的g.
  5. 每个P均有local runq, 大多数时间仅与local runq无锁交互.  新生成的g, 放入到local runq中.
  6. 调度时会随机从全局runq取g.  然后local runq, global runq... 均没有g的话, work stealing从其他P中取.
  7. sysmon: 对于运行过久的g设置抢占标识; 对于过久syscall的p, 进行m和p的分离. 防止p被占用过久影响调度.
  8. 封装了epoll, 网络fd会设置成NonBlocking模式, 网络fd的read, write, accept操作, 会以NonBlocking模式操作, 返回EAGAIN则gopark当前协程. 在m调度, sysmon中, gc start the world等阶段均会poll出ready的协程进行运行或者添加到全局runq中
  9. golang-1.12不支持非协作的抢占调度, 在密集CPU运算时, 可能会导致调度延迟. 官方已经解决.

  ![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200903193110.png)

### 5.操作系统-可靠UDP

- **UDT**
- **KCP**
- **QUIC**
  1. 内建安全性，集成TLS。连接建立过程和TLS协商过程合并，减少往返请求次数，提高连接速度。
  2. **集成多种拥塞算法**。包括最新的BBR多流支持，每个流有独立的拥塞控制，避免单个流中的丢包阻塞其它所有流（Head-of-line Blocking问题），更好的支持类似HTTP/2中的乱序请求。
  3. **连接迁移**。QUIC可以通过连接ID来唯一标识一个连接，当用户在有线、无线、移动网络之间切换时，可以保持上层连接的有效性，不需要再进行重连。
  4. 资料参考：https://juejin.im/post/6850418105462571021
- **uTP**
- **FASP(Aspera)**
- **SCTP(Stream Control Transmission Protocol)**

### 6.数据结构与算法-序列化

- **内置类型**
  1. 指编程语言内置支持的类型，如java的java.io.Serializable。
  2. 这种类型由于与语言绑定，不具有通用性，而且一般性能不佳，一般只在局部范围内使用。
- **文本类型**
  1. 一般是标准化的文本格式，如XML、JSON。
  2. 这种类型可读性较好，且支持跨平台，具有广泛的应用。主要缺点是比较臃肿，网络传输占用带宽大。
- **二进制类型**
  1. 采用二进制编码，数据组织更加紧凑，支持多语言和多平台。
  2. 常见的有`Protocol Buffer/Thrift/MessagePack/FlatBuffer`等。

### 7.空间换时间

- **报表**

  通过新建中间表，进行快速处理。

- **排行榜**

- **写扩散**

- **秒批**

  提前拉取用户信息，做好信息审批，然后等待用户发起请求。

### 8.代码优化

- **资源复用**

  内存池、线程池、连接池、对象池

- **异步**

  1. 调用异步化、流程异步化
  2. 异步-----对于处理耗时的任务，如果采用同步等待的方式，会严重降低系统的吞吐量，可以通过异步化进行解决。
  3. 异步在不同层面概念是有一些差异的，在这里我们不讨论异步I/O。

- **并发**

  请求并发、冗余请求

### 9.队列

![](https://javanote.oss-cn-shenzhen.aliyuncs.com/gogoyes/20200904115515.png)

- **主要作用**

  异步处理、流量削峰、系统解耦、数据同步、柔性事务

### 10.分片优化

- **分片策略**
  
  区间、hash、数据量、组合
  
- **二级索引**
  
  本地索引、全局索引
  
- **路由策略**
  
  客户端路由、代理层路由、集群路由
  
- **动态平衡**
  
  1. 固定分区：一致性哈希
  2. 动态分区：分裂、合并
  
- **分库分表**
  
  1. 垂直切分、水平切分
  2. 单表的数据量达到了一定的量级（如mysql一般为千万级），读写的性能会下降。这时索引也会很大，性能不佳，需要分解单表。
  
- **任务分片**
  
  Map/Reduce
  
  

### 11.存储优化

- **读写分离**

- **动静分离**

  评论和点赞

- **冷热分离**

  消息类、订单类

- **重写轻读**

- **数据异构**

  按照不同的维度建立索引关系以加速查询



## 架构学习

### 1.从开发到架构的进阶路线

- **从功能到架构** 
  
处理能力（吞吐量、延时、容量等）、伸缩性、容错性、扩展性、安全性（非功能性需求）
  
- **从测试性能到掌握性能**
  
Important skill: ability to estimate performance of a system design--without actually having to build it!
  
- **从正常到异常**
  
当系统在“非正常状况下”运行时，架构师应当让整个系统还是在控制下运行，而不是随机的、无序的。
  
- **从单机到集群**
  
  单机：CPU、内存管理、外存、网络、OS、RunTime
集群：机器、机架、电源、IDC、UPS、专线、电力、散热、地域、内网、公网、火灾、地震
  
- **从系统到服务**
  
  强大、有效的功能，良好的体验
  很高服务质量、可用性、性能等
  
- **具体实例**

  我们设计一个基于udp协议的批量好友资料拉取服务，每个好友资料40字节，用户发起的请求量为30万次/秒，4亿资料用户，平均好友数20个。架构师可以很快分析出业务模型，包量300K/s，流量2Gbps，存储量16G，资料若使用内存hash索引组织，hash查询量6M/s。通过量化性能分析，随即得出系统瓶颈在于CPU，主要消耗在hash查询，假设先不考虑容灾冗余，可使用8台4核处理器32G内存的box组成集群来支撑。不需要实现，架构师就可以模拟出运行时的场景，负载均衡到8台机器上，每台机器这时的cpu跑在大约60%，内存使用约60%，包量40K/s，流量300Mbps。

### 2.架构学习的具体方式

- **尽量简单(Keep It Simple and Stupid)**
  1. 通过分层、分模块的方式将复杂系统分解成关系清晰、松耦合的子系统
  2. 将复杂的逻辑隔离在一个尽可能小的范围内，提供简单的接口以与外部解耦，防止复杂性扩散

- **精准地把握**
  1. 依赖于对系统从上层到底层的深刻的认识，并且认识是定量、准确的
  2. 理论上的认知,工程上的经验

- **完备地设计**
  1. 用严谨的方法论来保证完备性
  2. 双重验证是另外一种常用的方法论

- **合理的tradeoff**
  1. 需要对系统的透彻地理解
  2. 正确认识需求及其优先级

